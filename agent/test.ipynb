{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908cf2c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StructureModel' object has no attribute 'to_dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m sm \u001b[38;5;241m=\u001b[39m from_pandas(df_scaled, w_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     20\u001b[0m sm\u001b[38;5;241m.\u001b[39mremove_edges_below_threshold(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m dot_str \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dot\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StructureModel' object has no attribute 'to_dot'"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any, List\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from causalnex.structure.notears import from_pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "with sqlite3.connect(\"data/bank.db\") as conn:\n",
    "    df = pd.read_sql_query(\"SELECT * FROM customer_data\", conn)\n",
    "\n",
    "# Encode categorical features\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].astype(\"category\").cat.codes\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled = df_scaled.fillna(0)\n",
    "\n",
    "sm = from_pandas(df_scaled, w_threshold=0.01, max_iter=1000)\n",
    "sm.remove_edges_below_threshold(0.01)\n",
    "dot_str = sm.to_dot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c36de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<causalnex.structure.structuremodel.StructureModel at 0x16a17148d60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b74bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "  income -> age;\n",
      "  income -> education;\n",
      "  income -> branch_visits;\n",
      "  income -> channel_preference;\n",
      "  income -> promotion_offer;\n",
      "  income -> customer_engagement;\n",
      "  education -> age;\n",
      "  education -> channel_preference;\n",
      "  education -> promotion_offer;\n",
      "  branch_visits -> age;\n",
      "  branch_visits -> education;\n",
      "  branch_visits -> channel_preference;\n",
      "  branch_visits -> region_code;\n",
      "  branch_visits -> promotion_offer;\n",
      "  channel_preference -> age;\n",
      "  promotion_offer -> age;\n",
      "  promotion_offer -> region_code;\n",
      "  customer_engagement -> age;\n",
      "  customer_engagement -> education;\n",
      "  customer_engagement -> branch_visits;\n",
      "  customer_engagement -> channel_preference;\n",
      "  customer_engagement -> promotion_offer;\n",
      "  activated_ib -> age;\n",
      "  activated_ib -> income;\n",
      "  activated_ib -> education;\n",
      "  activated_ib -> branch_visits;\n",
      "  activated_ib -> channel_preference;\n",
      "  activated_ib -> region_code;\n",
      "  activated_ib -> promotion_offer;\n",
      "  activated_ib -> customer_engagement;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dot_str = \"digraph {\\n\"\n",
    "for src, dst in sm.edges():\n",
    "    dot_str += f\"  {src} -> {dst};\\n\"\n",
    "dot_str += \"}\"\n",
    "print(dot_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7279a90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([('income', 'age'), ('income', 'education'), ('income', 'branch_visits'), ('income', 'channel_preference'), ('income', 'promotion_offer'), ('income', 'customer_engagement'), ('education', 'age'), ('education', 'channel_preference'), ('education', 'promotion_offer'), ('branch_visits', 'age'), ('branch_visits', 'education'), ('branch_visits', 'channel_preference'), ('branch_visits', 'region_code'), ('branch_visits', 'promotion_offer'), ('channel_preference', 'age'), ('promotion_offer', 'age'), ('promotion_offer', 'region_code'), ('customer_engagement', 'age'), ('customer_engagement', 'education'), ('customer_engagement', 'branch_visits'), ('customer_engagement', 'channel_preference'), ('customer_engagement', 'promotion_offer'), ('activated_ib', 'age'), ('activated_ib', 'income'), ('activated_ib', 'education'), ('activated_ib', 'branch_visits'), ('activated_ib', 'channel_preference'), ('activated_ib', 'region_code'), ('activated_ib', 'promotion_offer'), ('activated_ib', 'customer_engagement')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00d98e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Propensity Model Fitted Successfully\n",
      "Error instantiating catboost: No module named 'catboost'\n",
      "Error instantiating catboost: No module named 'catboost'\n",
      "[flaml.tune.tune: 06-28 19:30:12] {540} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 06-28 19:30:12] {811} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}, 'outcome_estimator': {'n_estimators': 100, 'max_features': 1.0, 'max_leaves': 4, 'estimator_name': 'random_forest'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "Component model time budget is 10. Recommended value is at least 300 for smallish datasets, 1800 for datasets with> 100K rows\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 06-28 19:30:15] {811} INFO - trial 2 config: {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}, 'outcome_estimator': {'alpha': 0.09999999999999991, 'fit_intercept': True, 'eps': 2.220446049250313e-16, 'estimator_name': 'lasso_lars'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 06-28 19:30:16] {811} INFO - trial 3 config: {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}, 'outcome_estimator': {'n_estimators': 100, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'estimator_name': 'lgbm'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 06-28 19:30:19] {811} INFO - trial 4 config: {'estimator': {'estimator_name': 'backdoor.econml.metalearners.TLearner'}, 'outcome_estimator': {'alpha': 0.09999999999999991, 'l1_ratio': 0.5, 'selection': 'cyclic', 'estimator_name': 'elastic_net'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hangh\\miniconda3\\envs\\python310\\lib\\site-packages\\causaltune\\optimiser.py:486\u001b[0m, in \u001b[0;36mCausalTune.fit\u001b[1;34m(self, data, treatment, outcome, common_causes, effect_modifiers, instruments, propensity_modifiers, estimator_list, resume, time_budget, preprocess, encoder_type, encoder_outcome, use_ray)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tune_with_config,\n\u001b[0;32m    488\u001b[0m         search_space,\n\u001b[0;32m    489\u001b[0m         metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric,\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# use_ray=self.use_ray,\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         cost_attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_cost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    492\u001b[0m         points_to_evaluate\u001b[38;5;241m=\u001b[39m(init_cfg \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_cfg) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_cfg),\n\u001b[0;32m    493\u001b[0m         evaluated_rewards\u001b[38;5;241m=\u001b[39m([] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_scores) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_scores),\n\u001b[0;32m    494\u001b[0m         mode\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;129;01min\u001b[39;00m metrics_to_minimize() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;66;03m# resources_per_trial= {\"cpu\": 1} if self.use_ray else None,\u001b[39;00m\n\u001b[0;32m    496\u001b[0m         low_cost_partial_config\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mget_best_trial() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hangh\\miniconda3\\envs\\python310\\lib\\site-packages\\flaml\\tune\\tune.py:462\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, force_cancel, n_concurrent_trials, **ray_args)\u001b[0m\n\u001b[0;32m    461\u001b[0m old_runner \u001b[38;5;241m=\u001b[39m _runner\n\u001b[1;32m--> 462\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ray_args, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mray_args is only valid when use_ray=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    464\u001b[0m     old_handlers\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(old_handlers[\u001b[38;5;241m0\u001b[39m], logging\u001b[38;5;241m.\u001b[39mStreamHandler)\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(old_handlers[\u001b[38;5;241m0\u001b[39m], logging\u001b[38;5;241m.\u001b[39mFileHandler)\n\u001b[0;32m    467\u001b[0m ):\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# Add the console handler.\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: ray_args is only valid when use_ray=True",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 42\u001b[0m\n\u001b[0;32m     33\u001b[0m ct \u001b[38;5;241m=\u001b[39m CausalTune(\n\u001b[0;32m     34\u001b[0m     estimator_list\u001b[38;5;241m=\u001b[39mestimators,\n\u001b[0;32m     35\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     outcome_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# run causaltune\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcomes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# return best estimator\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest estimator: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct\u001b[38;5;241m.\u001b[39mbest_estimator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hangh\\miniconda3\\envs\\python310\\lib\\site-packages\\causaltune\\optimiser.py:506\u001b[0m, in \u001b[0;36mCausalTune.fit\u001b[1;34m(self, data, treatment, outcome, common_causes, effect_modifiers, instruments, propensity_modifiers, estimator_list, resume, time_budget, preprocess, encoder_type, encoder_outcome, use_ray)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization failed! Did you set large enough time_budget and components_budget?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m         )\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;66;03m# we must have an older FLAML version that doesn't support the cost_attr parameter\u001b[39;00m\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tune_with_config,\n\u001b[0;32m    508\u001b[0m         search_space,\n\u001b[0;32m    509\u001b[0m         metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric,\n\u001b[0;32m    510\u001b[0m         points_to_evaluate\u001b[38;5;241m=\u001b[39m(init_cfg \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_cfg) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_cfg),\n\u001b[0;32m    511\u001b[0m         evaluated_rewards\u001b[38;5;241m=\u001b[39m([] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_scores) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_scores),\n\u001b[0;32m    512\u001b[0m         mode\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;129;01min\u001b[39;00m metrics_to_minimize() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    513\u001b[0m         low_cost_partial_config\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    515\u001b[0m     )\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# print(\"Optimization failed!\\n\", traceback.format_exc())\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;66;03m# raise e\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_summary_scores()\n",
      "File \u001b[1;32mc:\\Users\\hangh\\miniconda3\\envs\\python310\\lib\\site-packages\\flaml\\tune\\tune.py:814\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, force_cancel, n_concurrent_trials, **ray_args)\u001b[0m\n\u001b[0;32m    812\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PySparkOvertimeMonitor(time_start, time_budget_s, force_cancel):\n\u001b[1;32m--> 814\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_to_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\hangh\\miniconda3\\envs\\python310\\lib\\site-packages\\causaltune\\optimiser.py:552\u001b[0m, in \u001b[0;36mCausalTune._tune_with_config\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    550\u001b[0m     estimates \u001b[38;5;241m=\u001b[39m remote_exec(CausalTune\u001b[38;5;241m.\u001b[39m_estimate_effect, (\u001b[38;5;28mself\u001b[39m, config), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ray)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 552\u001b[0m     estimates \u001b[38;5;241m=\u001b[39m \u001b[43mremote_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCausalTune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_effect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_ray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m#     Parallel(n_jobs=2, backend=\"threading\")(\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m#     delayed(self._estimate_effect)(config) for i in range(1)\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m# ))[0]\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m estimates:\n",
      "File \u001b[1;32mc:\\Users\\hangh\\miniconda3\\envs\\python310\\lib\\site-packages\\causaltune\\remote.py:10\u001b[0m, in \u001b[0;36mremote_exec\u001b[1;34m(function, args, use_ray)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreading\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\hangh\\miniconda3\\envs\\python310\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hangh\\miniconda3\\envs\\python310\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hangh\\miniconda3\\envs\\python310\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any, List\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from dowhy import CausalModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from causaltune import CausalTune\n",
    "from causaltune.data_utils import CausalityDataset\n",
    "from causaltune.dataset_processor import CausalityDatasetProcessor\n",
    "from causalnex.structure.notears import from_pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from causalnex.structure import StructureModel\n",
    "from causalnex.structure.notears import from_numpy\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "with sqlite3.connect(\"data/bank.db\") as conn:\n",
    "    df = pd.read_sql_query(\"SELECT * FROM customer_data\", conn)\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "cd = CausalityDataset(data=df, treatment=\"promotion_offer\", outcomes=[\"activated_ib\"],\n",
    "                      common_causes=['age', 'income', 'education', 'branch_visits', 'channel_preference', 'region_code', 'customer_engagement'])\n",
    "cd.preprocess_dataset()\n",
    "\n",
    "estimators = [\"SLearner\", \"TLearner\", \"XLearner\"]\n",
    "base_learners = [\"random_forest\", \"neural_network\"]\n",
    "\n",
    "ct = CausalTune(\n",
    "    estimator_list=estimators,\n",
    "    metric=\"energy_distance\",\n",
    "    verbose=1,\n",
    "    components_time_budget=10, # in seconds trial for each model\n",
    "    outcome_model=\"auto\",\n",
    ")\n",
    "\n",
    "# run causaltune\n",
    "ct.fit(data=cd, outcome=cd.outcomes[0])\n",
    "\n",
    "# return best estimator\n",
    "print(f\"Best estimator: {ct.best_estimator}\")\n",
    "# config of best estimator:\n",
    "print(f\"Best config: {ct.best_config}\")\n",
    "# best score:\n",
    "print(f\"Best score: {ct.best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c4b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from dowhy import CausalModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from causaltune import CausalTune\n",
    "from causaltune.data_utils import CausalityDataset\n",
    "from causaltune.dataset_processor import CausalityDatasetProcessor\n",
    "from causalnex.structure.notears import from_pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from causalnex.structure import StructureModel\n",
    "from causalnex.structure.notears import from_numpy\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "with sqlite3.connect(\"data/bank.db\") as conn:\n",
    "    df = pd.read_sql_query(\"SELECT * FROM customer_data\", conn)\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "model = CausalModel(\n",
    "    data=df,\n",
    "    treatment=\"promotion_offer\",\n",
    "    outcome=\"activated_ib\",\n",
    "    common_causes=['age', 'income', 'education', 'branch_visits', 'channel_preference', 'region_code', 'customer_engagement'],\n",
    "    instruments=None,\n",
    "    effect_modifiers=None,\n",
    ")\n",
    "identified_estimand = model.identify_effect()\n",
    "estimate = model.estimate_effect(identified_estimand, method_name=\"backdoor.linear_regression\")\n",
    "\n",
    "\n",
    "# Run refutation methods\n",
    "refute_results = []\n",
    "refute_methods = [\n",
    "    \"placebo_treatment_refuter\",\n",
    "    \"random_common_cause\",\n",
    "    \"data_subset_refuter\"\n",
    "]\n",
    "for method in refute_methods:\n",
    "    refute = model.refute_estimate(identified_estimand, estimate, method_name=method)\n",
    "    refute_results.append({\"method\": method, \"result\": str(refute)})\n",
    "\n",
    "# print(refute_results)\n",
    "\n",
    "pass_test = all(\"fail\" not in r[\"result\"].lower() for r in refute_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d0b1618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'method': 'placebo_treatment_refuter',\n",
       "  'result': 'Refute: Use a Placebo Treatment\\nEstimated effect:0.23825513913622448\\nNew effect:6.943301029743054e-05\\np value:0.96\\n'},\n",
       " {'method': 'random_common_cause',\n",
       "  'result': 'Refute: Add a random common cause\\nEstimated effect:0.23825513913622448\\nNew effect:0.23822851960244631\\np value:0.8999999999999999\\n'},\n",
       " {'method': 'data_subset_refuter',\n",
       "  'result': 'Refute: Use a subset of data\\nEstimated effect:0.23825513913622448\\nNew effect:0.23826882687612905\\np value:0.96\\n'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refute_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068c3a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dcf368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
